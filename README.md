% Author: Jack Damiani
$ Project Started 4/20/22


Goal of the project:
Model Split Brain Syndrome

Description:
Split brain syndrome is the condition where a patient has a lesion of the corpus callosum. 
The condition was initially noticed from lesions to limit epileptic seizures, but it can be from other causes or purposes. 
Split brain syndrome creates a disconnect between the left and the right brain. 
The corpus callosum allows the two hemispheres to communicate. 
Many conditions have been observed, but in this case, visual and language disconnect will be modeled. 


Patients with lesion of the corpus callosum have been observed to not be able to verbally say what is viewed in the left visual field. 
This is because the language center of the brain is on the left side, and the visual field cortical representation is contralateral.
This means the right visual field is represented in the left cortex, where language is represented.
Likewise, the left visual field is represented in the right cortex, without verbal language representation. 
Patients with split brain syndrome will be able to verbally announce what is in the right visual field but will be silent or not know if an object is only in the left visual field.
They will, however, be able to draw what is in the left visual field with their left hand. 
Then, they would be able to say what that object is (if viewed with their right eye), but there is a disconnect on why they just drew that object. 
Patients will make up a reason for drawing that object.


In this project, only the verbal part of the project will be represented. 
There will be two input layers, represented as the left and right visual fields, represented by a 2D grid, split down the middle.
Objects will be presented.
After training occurs, only one side of the object will be shown for the test. 
In a normal patient, enough activation from the left or right side will be enough to activate the language output layer, only on the left cortical side. 
In a complete lesion, the right visual field will be able to achieve the correct output, but the left will not. 
Then, incomplete lesions will be analyzed to see the level of connectiveness needed to provide the correct verbal output from the left visual field.


The project will consist of two input layers, two hidden layers, and one output layer.
The input layers will be 10x5 each (making a 10x10 image).
Hidden layers will be 20x5, found by experimentation for ideal problem solving.
Output layers will be 1xI, where I is the number of images.


Citations:
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7305066/


Final Paper:
History of Split-Brain Syndrome
Split-Brain Syndrome (SBS) was discovered after initial reports in the 1940s by van Wagenen et. al (van Wagenen et al., 1942) and was quickly recognized as a new classification of cognitive state, leading to the discovery of various psychological phenomena. Initially, doctors lesioned the corpus callosum (CC) as an attempt to limit full cortical excitation during an epileptic attack. They were successful at limiting full cortical seizures, and the people were largely unaffected and able to live normal lives post-operation. However, psychologists were able to discover a variety of phenomena that occurred from the lack of connection between the two hemispheres. For timeline purposes, SBS was not discussed widespread as a concept until the 1960s (Gazzaniga et al., 1962). In addition, there are rare cases of hemorrhage or cancer that can lead to loss of the corpus callosum and lead to SBS in patients. The rest of the discussion will be on one phenomenon: visual discontinuity in SBS patients. 
One of the most well-known phenomena, visual discontinuity involves the contralateral nature of vision and the left cortical language representation in the brain. To be more precise, experiments involve presentation of simple objects in either the left or right visual field. Means of presentation may be on a screen while the head is fixed so only one eye can see the information or one eye may be covered. Thus, visual information travels contralaterally to the cortex, so the left eye, seeing the left visual field, only sends information to the right cortex. Conversely, the right eye, seeing the right visual field, only sends information to the left cortex. In a healthy patient, information is passed between the hemispheres through the CC, and nothing major is lost in interpretation. However, SBS patients, with a lesioned CC, lack this communication, notably leading to loss of language on the left visual field since information travels only to the right cortex, and language is represented only in the left cortex. 
This discovery led to a variety of interesting cases. The patient would easily name the object when presented in the right visual field, but then they would declare there was nothing in the right visual field. In many circumstances (MacKay et. al, 1982), patients demonstrated they still saw the object by motor movement on the left side of the body. The right hemisphere controls the left side of the body, so when presented with options, the left hand would still point to the correct object. In some cases, the person would be able to draw the object. A visual representation is shown in Figure 1. In both of these cases, however, the understanding of the object is a clear contradiction to the patient’s announcement that there was nothing presented. The patient when asked why they drew that object or how they knew the correct answer would be very confused and make up some untrue reason. There are still SBS papers posted annually. Learning more about this condition can give humanity a better understanding of how the healthy brain operates.
 
Figure 1: A SBS patient verbally reports that nothing is shown on the screen, but is able to draw the image with the hand on the ipsilateral visual field.
Project Description
In this project, emergent will only be used to model the part of visual discontinuity where the person correctly or incorrectly verbally says the object. The neural structure is very simplified. It will involve two input layers, representing the left (InputL) and right (InputR) visual fields. Then, the input layers will be unidirectionally connected to the contralateral cortical representation. The InputL layer will be connected to the right Hidden layer, (HiddenR), and the InputR layer will be connected to the left Hidden layer (HiddenL). The target or output layer will simply identify the object, but it will only be representative of language, and thus it will only be in the left cortex (OutputL), and it will only be connected to the left cortical hidden layer (HiddenL). In a normal patient, the two hidden layers will be completely bidirectionally connected, and in the SBS the two hidden layers will be completely lesioned, with no connection. Incomplete lesioning will be attempted as well, trying to discover the threshold for how much information needs to be passed from the right cortical representation to the left before the language output layer accurately provides information. 
Network
The network is organized into 5 layers: 2 input layers, 2 hidden layers, and 1 output layer. The two input layers are separate representations of vision, so I placed them right next to each other to make it look like vision. Both layers are 10 rows by 5 columns. These input layers are unidirectionally connected to the contralateral hidden layer. InputL is only connected to HiddenR, and InputR is only connected to HiddenL. The hidden layers arbitrarily consist of 20 rows by 5 columns. This number was chosen since it is more nodes than the respective input layers for analysis, but not too many layers that information is lost. In a healthy patient, the two hidden layers are bidirectionally connected completely. In a SBS patient, the projection is completely lesioned, although I couldn’t figure out how to do that, so I used a different technique discussed later. Finally, there is an output layer that is 1 row by i columns, where i represents the number of test trial options. Currently, there are 3 outputs, so OutputL is 1 row by 3 columns. OuputL is bidirectionally connected to only the HiddenL layer, as language output is only represented on the left side. The network is shown in Figure 1. 
 
Figure 2: Network Representation
Guide
This section is a quick guide of how to use the sim with the assumption that the user understands other sims. The train button does not work at this moment. Instead, to see results, press the test trial button through the data. The TrnEpcPlot Tab doesn’t work, but the TstTrlPlot will show results. Lesion can be used to lesion the corpus callosum. At this moment it is not completely functional. I had to work around lesioning the projection between hidden layers, so changing Lesion from 0 to 1 should lesion the left hidden layer and changing from 0 to 2 should lesion the right hidden layer. Prop changes the proportion of the layer that is lesioned to model incomplete corpus callosum lesions. However, these functions are not finished at the moment. 
Implementation
	First, discussion will begin with how the inputs were organized. There were 3 classifications that were options for the output layer. There is T, Snowman, and Happy. All are represented with the two input layers. All the options I made were symmetrical for the inputs. They provide opposite representations because it is a reflection over the vertical axis at the separation between the two layers. At this moment, I’m struggling to get the code to work how I want it, so I’ll discuss my plan. I was initially going to test how the network worked while training it with inputs coming from both input layers, as the patient sees it with both eyes. Since the right visual field activates the left cortex with language, both healthy and SBS patients would be able to output the correct response. Then, I was going to test, as the experimenters did with just one visual field activated, either the left or the right. Ideally, the results would demonstrate that in healthy patients activation of either visual field would give a correct output. However, I hypothesized that this tactic may not work since the training would learn based on both hidden layers’ representations, and activation of only one may only activate the wrong output. Therefore, my second tactic was to train the data using only input from one visual field. Thus, the hidden layer representations will be more accurate to the correct output for the testing data. As of now, the input representation is not broken up into both inputs, left inputs, and right inputs. They are all just together. The representation is shown in Figure 2.
   
Figure 3: The left side has input from both the left and right visual field. The right side has input from only the right visual field. These are both in a healthy patient. 

Next, I will discuss how I attempted to do lesioning. I couldn’t figure out how to lesion just a projection, which was the goal, but I found a way around it. One can lesion a whole layer by turning all the activation off. Therefore, turning off one of the hidden layers is the same as the projections not communicating with it. For instance, when presenting information to just the right visual field (activating InputR), of the hidden layers, only the HiddenL layer would be activated in a SBS patient. Therefore, lesioning the whole HiddenR layer would accomplish this goal. Likewise, for activating the InputL layer, only the HiddenR layer will be active, so lesioning the HiddenL layer will accomplish this goal. However, this then has the issue that HiddenR cannot activate OutputL at all. Originally, I thought it would be reasonable to represent the OutputL layer turning on with inaccurate results, but more accurately, OutputL wouldn’t be activated at all from SBS patients with information only in the left visual field. Therefore, this representation makes sense. As of now, if you change the lesioning value from 0 to 1 or 2, both lesion the HiddenL layer. It does break the structure of the nodes, so it is not finished. Likewise, data from the InputR layer still provides weights for the HiddenR layer, which is inaccurate and would have to be fixed. 
	Finally, I’ll talk about weight representations. Since I used a lot of the code from the face_categ sim in chapter 3, I kept most of those weights for the representations of the layers. I thought this made sense since there was an input layer, and an option for identity, which is representative of my OutputL layer. I spent some time applying different parameters to the data, but ultimately, the train function would uncover the appropriate parameters. Therefore, I just left the data as is, which is inaccurate. 
Discussion and Future Studies
	My expected results are fairly simple: the network should be 100% accurate in healthy patients all trials. In SBS patients with lesioning, they should be 100% accurate with only InputR input, representative of the right visual field. However, they should be 0% accurate when only InputL input, representative of the left visual field. I am unsure the results of incomplete lesioning, but I hypothesize that the more lesioning that occurs, the less accurate the results will be. 
	Given more time, I would fix the following issues I had with the code. Principally, I never got Train to function properly. Therefore, the network was never able to accurately learn the data before lesioning. I messed with the weights of the layers enough that T is very accurately represented, but there is a disparity between Snowman and Happy. I also was unable to get the TrnEpcPlot graphing functionality to work. This would have helped me visualize that the training data was 100% accurate. Additionally, I would have added more testing data. All of the visual inputs I have are symmetrical, but it would be interesting to analyze how the network responds to nonsymmetrical characters like an R or a 7. This is indicative of how a SBS patient’s perspective can change with differing information placed in front of them. Luckily, the left visual field is represented in both eyes. The right part of each eye captures light from the left visual field, that then goes to both hemisphere’s cortices. Therefore, a SBS patient wouldn’t have to struggle with conflicting information often in their life. There is some point in space where only the left eye can see the left visual field, but that issue can be solved by the SBS patient turning their head more. It is unlikely someone with SBS would suffer from the visual discontinuity principle discussed, but it does present a lot of information on how the two hemispheres communicate with one another and operate separately. 
	Next, I would have developed the lesion button. Since I couldn’t figure out how to lesion just the projection, I think that lesioning the layers was a good option. However, this would require classification of the training data in a different manner. This is because it doesn’t make sense to present the InputR data to a lesioned HiddenL layer or the other way around. Getting the lesion button to work would likely represent what I want it to because it eliminates the output completely. However, an interesting study would be the effect of partial lesioning. This can occur when a tumor or hemorrhage leads to neuronal death of the corpus callosum. For example, Marchiava-Bignami disease leads to demyelination and neuron death of the CC (Goldstein et. al (2021). This is a rare condition but modelling it could lead to fundamental discoveries about how the two hemispheres communicate. 
	Finally, this is a very simplified model of how the visual system interacts with cortical representations of vision and language. This of course is a very complicated process to which we don’t understand completely. By creating a more complicated but biologically accurate representation of the pathway between the retinal ganglia cells in the eye, the visual cortex, and the language center of the brain could provide discoveries and information about the interconnectedness of this pathway. 
Conclusion
	In conclusion, I was unable to complete the representation of Split-Brain Syndrome in emergent. However, I was able to accomplish a large part of the modelling. I was able to model the layers how I wanted them. I was able to input testing data, and have the connectedness of the network output a result. There needs to be further steps in improving the training and lesioning areas of the data. Likewise, parameters need to be optimized. Perhaps the number of nodes in the Hidden Layer was not optimal, or the initial parameters of inhibition and activation were not optimal. There needs to be more experimentation with different designs to find these values. After all of this is done, incomplete lesioning and varieties of inputs can be tested. Split-Brain Syndrome and representations of partial lesioning of the Corpus Callosum has a lot to teach humanity about how the two hemispheres operate together and independently. Modelling of the brain is always preferred over in patient studies since clinical trials for this condition are rare, expensive, and invasive technologies would likely be needed to analyze data. 



